"""Learning Engine - –æ–±—É—á–∞–µ—Ç Domain Parser –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Comet."""
import json
import re
import os
from datetime import datetime
from typing import Dict, List, Optional
from urllib.parse import urlparse
import logging

logger = logging.getLogger(__name__)


class LearningEngine:
    """–î–≤–∏–∂–æ–∫ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è Domain Parser."""
    
    def __init__(self, patterns_file: str = None):
        """
        Args:
            patterns_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤—ã—É—á–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
        """
        if patterns_file is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            patterns_file = os.path.join(current_dir, "learning_patterns.json")
        
        self.patterns_file = patterns_file
        self.patterns = self._load_patterns()
    
    def _load_patterns(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—ã—É—á–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞."""
        if not os.path.exists(self.patterns_file):
            return {
                "version": "1.0",
                "last_updated": None,
                "learned_patterns": {
                    "inn_patterns": [],
                    "email_patterns": [],
                    "successful_urls": {
                        "inn": [],
                        "email": []
                    },
                    "domain_specific": {}
                },
                "statistics": {
                    "total_learned": 0,
                    "comet_contributions": 0,
                    "success_rate_before": 0.0,
                    "success_rate_after": 0.0
                }
            }
        
        try:
            with open(self.patterns_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error loading patterns: {e}")
            return self._load_patterns()  # Return default
    
    def _save_patterns(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—ã—É—á–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Ñ–∞–π–ª."""
        try:
            self.patterns["last_updated"] = datetime.now().isoformat()
            with open(self.patterns_file, 'w', encoding='utf-8') as f:
                json.dump(self.patterns, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ Patterns saved to {self.patterns_file}")
        except Exception as e:
            logger.error(f"Error saving patterns: {e}")
    
    def learn_from_comet_success(
        self,
        domain: str,
        comet_result: Dict,
        parser_result: Dict,
        learning_session_id: str = None
    ) -> Dict:
        """
        –û–±—É—á–∏—Ç—å—Å—è –Ω–∞ —É—Å–ø–µ—à–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ Comet, –∫–æ–≥–¥–∞ Domain Parser –Ω–µ –Ω–∞—à–µ–ª –¥–∞–Ω–Ω—ã–µ.
        
        Args:
            domain: –î–æ–º–µ–Ω, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–µ–º—Å—è
            comet_result: –†–µ–∑—É–ª—å—Ç–∞—Ç Comet (—Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ò–ù–ù/Email)
            parser_result: –†–µ–∑—É–ª—å—Ç–∞—Ç Domain Parser (–Ω–µ –Ω–∞—à–µ–ª –¥–∞–Ω–Ω—ã–µ)
            learning_session_id: ID —Å–µ—Å—Å–∏–∏ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–º, —á—Ç–æ –±—ã–ª–æ –≤—ã—É—á–µ–Ω–æ
        """
        learned = {
            "domain": domain,
            "timestamp": datetime.now().isoformat(),
            "session_id": learning_session_id,
            "learned_items": []
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Comet –Ω–∞—à–µ–ª –¥–∞–Ω–Ω—ã–µ, –∞ Parser - –Ω–µ—Ç
        comet_inn = comet_result.get("inn")
        comet_email = comet_result.get("email")
        parser_inn = parser_result.get("inn")
        parser_email = parser_result.get("email")
        
        source_urls = comet_result.get("sourceUrls", [])
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ò–ù–ù
        if comet_inn and not parser_inn:
            inn_learning = self._learn_inn_pattern(domain, comet_inn, source_urls)
            if inn_learning:
                learned["learned_items"].append(inn_learning)
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ Email
        if comet_email and not parser_email:
            email_learning = self._learn_email_pattern(domain, comet_email, source_urls)
            if email_learning:
                learned["learned_items"].append(email_learning)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if learned["learned_items"]:
            self.patterns["statistics"]["total_learned"] += len(learned["learned_items"])
            self.patterns["statistics"]["comet_contributions"] += 1
            self._save_patterns()
            
            logger.info(f"üìö Learned {len(learned['learned_items'])} patterns from {domain}")
        
        return learned
    
    def _learn_inn_pattern(self, domain: str, inn: str, source_urls: List[str]) -> Optional[Dict]:
        """–í—ã—É—á–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –ò–ù–ù."""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º URL, –≥–¥–µ –±—ã–ª –Ω–∞–π–¥–µ–Ω –ò–ù–ù
        url_patterns = self._extract_url_patterns(source_urls)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ URL –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in url_patterns:
            if pattern not in self.patterns["learned_patterns"]["successful_urls"]["inn"]:
                self.patterns["learned_patterns"]["successful_urls"]["inn"].append(pattern)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º domain-specific –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if domain not in self.patterns["learned_patterns"]["domain_specific"]:
            self.patterns["learned_patterns"]["domain_specific"][domain] = {
                "inn_urls": [],
                "email_urls": [],
                "inn_found_count": 0,
                "email_found_count": 0
            }
        
        self.patterns["learned_patterns"]["domain_specific"][domain]["inn_urls"].extend(source_urls)
        self.patterns["learned_patterns"]["domain_specific"][domain]["inn_found_count"] += 1
        
        return {
            "type": "inn",
            "value": inn,
            "source_urls": source_urls,
            "url_patterns": url_patterns,
            "learning": f"–¢–µ–ø–µ—Ä—å –±—É–¥—É –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–∏–ø–∞: {', '.join(url_patterns[:3])}"
        }
    
    def _learn_email_pattern(self, domain: str, email: str, source_urls: List[str]) -> Optional[Dict]:
        """–í—ã—É—á–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ Email."""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º URL, –≥–¥–µ –±—ã–ª –Ω–∞–π–¥–µ–Ω Email
        url_patterns = self._extract_url_patterns(source_urls)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ URL –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in url_patterns:
            if pattern not in self.patterns["learned_patterns"]["successful_urls"]["email"]:
                self.patterns["learned_patterns"]["successful_urls"]["email"].append(pattern)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º domain-specific –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if domain not in self.patterns["learned_patterns"]["domain_specific"]:
            self.patterns["learned_patterns"]["domain_specific"][domain] = {
                "inn_urls": [],
                "email_urls": [],
                "inn_found_count": 0,
                "email_found_count": 0
            }
        
        self.patterns["learned_patterns"]["domain_specific"][domain]["email_urls"].extend(source_urls)
        self.patterns["learned_patterns"]["domain_specific"][domain]["email_found_count"] += 1
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω email –¥–æ–º–µ–Ω–∞
        email_domain = email.split('@')[-1] if '@' in email else None
        if email_domain:
            email_pattern = f"*@{email_domain}"
            if email_pattern not in self.patterns["learned_patterns"]["email_patterns"]:
                self.patterns["learned_patterns"]["email_patterns"].append(email_pattern)
        
        return {
            "type": "email",
            "value": email,
            "source_urls": source_urls,
            "url_patterns": url_patterns,
            "learning": f"–¢–µ–ø–µ—Ä—å –±—É–¥—É –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–∏–ø–∞: {', '.join(url_patterns[:3])}"
        }
    
    def _extract_url_patterns(self, urls: List[str]) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ URL (–Ω–∞–ø—Ä–∏–º–µ—Ä, /contacts, /about, /requisites)."""
        patterns = []
        
        for url in urls:
            try:
                parsed = urlparse(url)
                path = parsed.path.lower()
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏ –ø—É—Ç–∏
                if '/contact' in path:
                    patterns.append('/contacts')
                elif '/about' in path:
                    patterns.append('/about')
                elif '/requisite' in path or '/rekvizit' in path:
                    patterns.append('/requisites')
                elif '/company' in path or '/kompan' in path:
                    patterns.append('/company')
                elif '/info' in path:
                    patterns.append('/info')
                elif path and path != '/':
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç –ø—É—Ç–∏
                    segments = [s for s in path.split('/') if s]
                    if segments:
                        patterns.append(f'/{segments[0]}')
            except Exception:
                continue
        
        return list(set(patterns))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    def get_priority_urls(self, domain: str, data_type: str = "both") -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—É—á–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
        
        Args:
            domain: –î–æ–º–µ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            data_type: "inn", "email" –∏–ª–∏ "both"
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö URL –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        priority_urls = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º domain-specific –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        domain_data = self.patterns["learned_patterns"]["domain_specific"].get(domain, {})
        
        if data_type in ["inn", "both"]:
            priority_urls.extend(domain_data.get("inn_urls", []))
            priority_urls.extend(self.patterns["learned_patterns"]["successful_urls"]["inn"])
        
        if data_type in ["email", "both"]:
            priority_urls.extend(domain_data.get("email_urls", []))
            priority_urls.extend(self.patterns["learned_patterns"]["successful_urls"]["email"])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set()
        unique_urls = []
        for url in priority_urls:
            if url not in seen:
                seen.add(url)
                unique_urls.append(url)
        
        return unique_urls
    
    def get_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—É—á–µ–Ω–∏—è."""
        return self.patterns["statistics"]
    
    def get_learned_summary(self, limit: int = 10) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –≤—ã—É—á–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
        return {
            "total_patterns": len(self.patterns["learned_patterns"]["successful_urls"]["inn"]) + 
                            len(self.patterns["learned_patterns"]["successful_urls"]["email"]),
            "inn_url_patterns": self.patterns["learned_patterns"]["successful_urls"]["inn"][:limit],
            "email_url_patterns": self.patterns["learned_patterns"]["successful_urls"]["email"][:limit],
            "domains_learned": len(self.patterns["learned_patterns"]["domain_specific"]),
            "statistics": self.patterns["statistics"]
        }

"""Domain Info Parser - –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ò–ù–ù –∏ email —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü."""
import re
import asyncio
from typing import Optional, Dict, List
from urllib.parse import urljoin, urlparse
import logging

from playwright.async_api import async_playwright, Browser, Page, TimeoutError as PlaywrightTimeout

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DomainInfoParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ò–ù–ù –∏ email —Å –¥–æ–º–µ–Ω–æ–≤."""
    
    def __init__(self, headless: bool = True, timeout: int = 15000):
        """
        Args:
            headless: –ó–∞–ø—É—Å–∫–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä –≤ headless —Ä–µ–∂–∏–º–µ
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self.headless = headless
        self.timeout = timeout
        self.browser: Optional[Browser] = None
        self.playwright = None
        
    async def start(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä."""
        logger.info("–ó–∞–ø—É—Å–∫ Playwright...")
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=self.headless)
        logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω")
        
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å –±—Ä–∞—É–∑–µ—Ä."""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
    
    def extract_inn(self, text: str, html: str = "") -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å –ò–ù–ù –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ HTML —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏."""
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ò–ù–ù —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        inn_patterns = [
            # –ö–†–ò–¢–ò–ß–ù–û: –§–æ—Ä–º–∞—Ç –ò–ù–ù/–ö–ü–ü —Å –∫–æ—Å–æ–π —á–µ—Ä—Ç–æ–π (—Å–∞–º—ã–π —á–∞—Å—Ç—ã–π —Å–ª—É—á–∞–π!)
            r'–ò–ù–ù[/\s]*–ö–ü–ü[:\s]*(\d{10})[/\s]+\d{9}',  # –ò–ù–ù/–ö–ü–ü: 7703412988/772001001
            r'–ò–ù–ù[/\s]*–ö–ü–ü[:\s\n]+(\d{10})[\s/]+\d{9}',  # –ò–ù–ù/–ö–ü–ü 7703412988/772001001
            r'(?:–ò–ù–ù|INN)[/\s]*(?:–ö–ü–ü|KPP)[:\s]*(\d{10})[/\s]+\d{9}',  # INN/KPP: 7703412988/772001001
            
            # –ü—Ä—è–º–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ò–ù–ù (—Å —É—á–µ—Ç–æ–º –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤)
            r'–ò–ù–ù[:\s\n]+(\d{10}|\d{12})',
            r'INN[:\s\n]+(\d{10}|\d{12})',
            r'–∏–Ω–Ω[:\s\n]+(\d{10}|\d{12})',
            
            # –° —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
            r'–ò–ù–ù[:\s\n]+(\d{4}[\s\-\n]?\d{6})',  # –ò–ù–ù: 1234 567890
            r'–ò–ù–ù[:\s\n]+(\d{4}[\s\-\n]?\d{4}[\s\-\n]?\d{4})',  # –ò–ù–ù: 1234 5678 9012
            
            # –í —Ç–∞–±–ª–∏—Ü–∞—Ö/—Ä–µ–∫–≤–∏–∑–∏—Ç–∞—Ö
            r'(?:—Ä–µ–∫–≤–∏–∑–∏—Ç|requisite|details|—é—Ä–∏–¥–∏—á–µ—Å–∫).*?–ò–ù–ù[:\s\n]*(\d{10}|\d{12})',
            r'(?:—Ä–µ–∫–≤–∏–∑–∏—Ç|requisite|details|legal).*?INN[:\s\n]*(\d{10}|\d{12})',
            
            # –†—è–¥–æ–º —Å –û–ì–†–ù/–ö–ü–ü
            r'(?:–û–ì–†–ù|OGRN)[:\s\n]+\d+.*?–ò–ù–ù[:\s\n]*(\d{10}|\d{12})',
            r'(?:–ö–ü–ü|KPP)[:\s\n]+\d+.*?–ò–ù–ù[:\s\n]*(\d{10}|\d{12})',
            
            # –í –∫–æ–Ω—Ç–∞–∫—Ç–∞—Ö/–æ –∫–æ–º–ø–∞–Ω–∏–∏
            r'(?:–æ –∫–æ–º–ø–∞–Ω–∏–∏|about|–∫–æ–Ω—Ç–∞–∫—Ç|contact|company).*?–ò–ù–ù[:\s\n]*(\d{10}|\d{12})',
            
            # –í —Ñ—É—Ç–µ—Ä–µ
            r'(?:footer|–ø–æ–¥–≤–∞–ª).*?–ò–ù–ù[:\s\n]*(\d{10}|\d{12})',
        ]
        
        # –ò—â–µ–º —Å —è–≤–Ω—ã–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –ò–ù–ù –≤ —Ç–µ–∫—Å—Ç–µ
        for pattern in inn_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            for match in matches:
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –¥–µ—Ñ–∏—Å—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
                clean_match = re.sub(r'[\s\-\n]', '', match)
                if len(clean_match) in [10, 12]:
                    logger.info(f"Found INN with pattern in text: {clean_match}")
                    return clean_match
        
        # –ò—â–µ–º –≤ HTML (–µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω)
        if html:
            # –ü–æ–∏—Å–∫ –≤ meta-—Ç–µ–≥–∞—Ö
            meta_patterns = [
                r'<meta[^>]*name=["\']inn["\'][^>]*content=["\'](\d{10}|\d{12})["\']',
                r'<meta[^>]*property=["\']inn["\'][^>]*content=["\'](\d{10}|\d{12})["\']',
                r'<meta[^>]*content=["\'](\d{10}|\d{12})["\'][^>]*name=["\']inn["\']',
            ]
            
            for pattern in meta_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE)
                if matches:
                    logger.info(f"Found INN in meta tag: {matches[0]}")
                    return matches[0]
            
            # –ü–æ–∏—Å–∫ –≤ data-–∞—Ç—Ä–∏–±—É—Ç–∞—Ö
            data_patterns = [
                r'data-inn=["\'](\d{10}|\d{12})["\']',
                r'data-company-inn=["\'](\d{10}|\d{12})["\']',
            ]
            
            for pattern in data_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE)
                if matches:
                    logger.info(f"Found INN in data attribute: {matches[0]}")
                    return matches[0]
            
            # –ü–æ–∏—Å–∫ –≤ HTML —Å —è–≤–Ω—ã–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –ò–ù–ù
            for pattern in inn_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    clean_match = re.sub(r'[\s\-\n]', '', match)
                    if len(clean_match) in [10, 12]:
                        logger.info(f"Found INN with pattern in HTML: {clean_match}")
                        return clean_match
            
            # –ü–æ–∏—Å–∫ –≤ JavaScript-–∫–æ–Ω—Ç–µ–Ω—Ç–µ (–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –æ–±—ä–µ–∫—Ç—ã, JSON)
            js_patterns = [
                r'["\']inn["\']\s*:\s*["\']?(\d{10}|\d{12})["\']?',  # "inn": "7820067929"
                r'inn\s*=\s*["\']?(\d{10}|\d{12})["\']?',  # inn = "7820067929"
                r'companyInn["\']?\s*:\s*["\']?(\d{10}|\d{12})["\']?',  # companyInn: "7820067929"
                r'data\.inn\s*=\s*["\']?(\d{10}|\d{12})["\']?',  # data.inn = "7820067929"
            ]
            
            for pattern in js_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE)
                if matches:
                    logger.info(f"Found INN in JavaScript content: {matches[0]}")
                    return matches[0]
            
            # –ê–ì–†–ï–°–°–ò–í–ù–´–ô –ü–û–ò–°–ö: –∏—â–µ–º –ª—é–±—ã–µ 10/12-–∑–Ω–∞—á–Ω—ã–µ —á–∏—Å–ª–∞ –≤ HTML —Ä—è–¥–æ–º —Å–æ —Å–ª–æ–≤–∞–º–∏ –ò–ù–ù/INN
            aggressive_patterns = [
                r'(?:–ò–ù–ù|INN|–∏–Ω–Ω)[^\d]{0,50}(\d{10}|\d{12})',  # –ò–ù–ù –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 50 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç —á–∏—Å–ª–∞
                r'(\d{10}|\d{12})[^\d]{0,50}(?:–ò–ù–ù|INN|–∏–Ω–Ω)',  # –ß–∏—Å–ª–æ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 50 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç –ò–ù–ù
            ]
            
            for pattern in aggressive_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    clean_match = re.sub(r'[\s\-\n]', '', match)
                    if len(clean_match) in [10, 12] and not clean_match.startswith(('7', '8', '9')):
                        logger.info(f"Found INN with aggressive pattern in HTML: {clean_match}")
                        return clean_match
        
        # –ü–æ–∏—Å–∫ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ "—Ä–µ–∫–≤–∏–∑–∏—Ç—ã" –∏–ª–∏ "–æ –∫–æ–º–ø–∞–Ω–∏–∏" —Å –±–æ–ª—å—à–∏–º –æ–∫–Ω–æ–º
        context_patterns = [
            r'(?:—Ä–µ–∫–≤–∏–∑–∏—Ç|requisite|–æ –∫–æ–º–ø–∞–Ω–∏–∏|about|details|company info|—é—Ä–∏–¥–∏—á–µ—Å–∫|legal).{0,500}?(\d{10}|\d{12})',
        ]
        
        for pattern in context_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            for match in matches[:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                if len(match) in [10, 12] and not match.startswith(('7', '8', '9')):
                    logger.info(f"Found INN in context: {match}")
                    return match
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å —è–≤–Ω—ã–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º, –∏—â–µ–º 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥
        # –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –æ–∫—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏–ª–∏ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        general_pattern = r'(?<!\d)(\d{10}|\d{12})(?!\d)'
        matches = re.findall(general_pattern, text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –∏—Å–∫–ª—é—á–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –∏ –¥—Ä—É–≥–∏–µ —á–∏—Å–ª–∞
        for match in matches:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–µ–ª–µ—Ñ–æ–Ω (–Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 7, 8, 9)
            if len(match) == 10 and not match.startswith(('7', '8', '9')):
                logger.info(f"Found potential INN (10 digits): {match}")
                return match
            elif len(match) == 12:
                # –î–ª—è 12-–∑–Ω–∞—á–Ω—ã—Ö –ò–ù–ù (–ò–ü) –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 79 (—Ç–µ–ª–µ—Ñ–æ–Ω)
                if not match.startswith('79'):
                    logger.info(f"Found potential INN (12 digits, IP): {match}")
                    return match
        
        logger.info("No INN found in text")
        return None
    
    def extract_emails(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å email –∞–¥—Ä–µ—Å–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        emails = re.findall(pattern, text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –∏—Å–∫–ª—é—á–∞–µ–º –æ–±—â–∏–µ email-–∞–¥—Ä–µ—Å–∞ —Ç–∏–ø–∞ example@example.com
        filtered = []
        exclude_patterns = ['example', 'test', 'domain', 'email', 'yoursite', 'yourdomain']
        
        for email in emails:
            email_lower = email.lower()
            if not any(pattern in email_lower for pattern in exclude_patterns):
                filtered.append(email)
        
        return list(set(filtered))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    async def get_page_text(self, page: Page) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ body
            text = await page.evaluate('''() => {
                return document.body.innerText;
            }''')
            return text
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return ""
    
    async def find_contact_pages(self, page: Page, base_url: str) -> List[str]:
        """–ù–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏."""
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü —Å —Ä–µ–∫–≤–∏–∑–∏—Ç–∞–º–∏
        contact_keywords = [
            '–∫–æ–Ω—Ç–∞–∫—Ç', 'contact', '–æ –∫–æ–º–ø–∞–Ω–∏–∏', '–∫–æ–º–ø–∞–Ω–∏', 'about', 
            '—Ä–µ–∫–≤–∏–∑–∏—Ç', '—Ä–µ–∫–≤–∏–∑–∏—Ç—ã', 'requisites',
            'politics', 'company', '—é—Ä–∏–¥–∏—á–µ—Å–∫', 'legal', 'details', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'
        ]
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ URL
        url_keywords = [
            'contact', 'about', 'requisites', 'requisite', 'politics', 
            'company', 'legal', 'details', 'o-kompanii', 'kompanii'
        ]
        contact_urls = []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            links = await page.evaluate('''() => {
                return Array.from(document.querySelectorAll('a[href]')).map(a => ({
                    href: a.href,
                    text: a.innerText.toLowerCase()
                }));
            }''')
            
            for link in links:
                href = link['href']
                text = link['text']
                href_lower = href.lower()
                text_lower = text.lower()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏ –ò–õ–ò URL (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
                text_match = any(keyword in text_lower for keyword in contact_keywords)
                url_match = any(keyword in href_lower for keyword in url_keywords)
                
                if text_match or url_match:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π URL
                    full_url = urljoin(base_url, href)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–æ—Ç –∂–µ –¥–æ–º–µ–Ω
                    if urlparse(full_url).netloc == urlparse(base_url).netloc:
                        contact_urls.append(full_url)
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü: {e}")
        
        return list(set(contact_urls))[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 —Å—Ç—Ä–∞–Ω–∏—Ü
    
    async def parse_domain(self, domain: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏—Ç—å –¥–æ–º–µ–Ω –∏ –∏–∑–≤–ª–µ—á—å –ò–ù–ù –∏ email.
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, example.com)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {domain, inn, emails, source_urls, error}
        """
        if not self.browser:
            raise Exception("–ë—Ä–∞—É–∑–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω. –í—ã–∑–æ–≤–∏—Ç–µ start() —Å–Ω–∞—á–∞–ª–∞.")
        
        result = {
            'domain': domain,
            'inn': None,
            'emails': [],
            'source_urls': [],
            'error': None
        }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL
        url = f"https://{domain}" if not domain.startswith('http') else domain
        base_url = url
        
        logger.info(f"üîç –ü–∞—Ä—Å–∏–Ω–≥: {domain}")
        
        page = await self.browser.new_page()
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            logger.info(f"  ‚Üí –ó–∞–≥—Ä—É–∑–∫–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            await page.goto(url, wait_until='domcontentloaded', timeout=self.timeout)
            result['source_urls'].append(page.url)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏ HTML –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            main_text = await self.get_page_text(page)
            main_html = await page.content()
            
            # –ò—â–µ–º –ò–ù–ù –∏ email –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            inn = self.extract_inn(main_text, main_html)
            emails = self.extract_emails(main_text)
            
            if inn:
                result['inn'] = inn
                logger.info(f"  ‚úÖ –ò–ù–ù –Ω–∞–π–¥–µ–Ω –Ω–∞ –≥–ª–∞–≤–Ω–æ–π: {inn}")
            
            if emails:
                result['emails'].extend(emails)
                logger.info(f"  ‚úÖ Email –Ω–∞–π–¥–µ–Ω –Ω–∞ –≥–ª–∞–≤–Ω–æ–π: {emails}")
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ò–ù–ù –∏–ª–∏ email, –∏—â–µ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö
            if not inn or not emails:
                logger.info(f"  ‚Üí –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü...")
                contact_urls = await self.find_contact_pages(page, base_url)
                
                # –ï—Å–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à–µ–ª —Å—Ç—Ä–∞–Ω–∏—Ü, –ø—Ä–æ–±—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ URL
                if not contact_urls:
                    logger.info(f"  ‚Üí –ü—Ä–æ–±—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ URL...")
                    common_paths = [
                        '/pages/requisites/', '/requisites/', '/requisites', 
                        '/company/', '/company', '/about/', '/about',
                        '/contacts/', '/contacts', '/politics/', '/politics',
                        '/legal/', '/legal', '/details/', '/details',
                        '/o-kompanii.html', '/o-kompanii/', '/about/contacts/',
                        '/service/legal/', '/kontakty.html', '/kontakty/'
                    ]
                    for path in common_paths:
                        test_url = urljoin(base_url, path)
                        try:
                            response = await page.goto(test_url, wait_until='domcontentloaded', timeout=10000)
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
                            if response and response.ok:
                                contact_urls.append(page.url)
                                logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {path}")
                                break  # –ù–∞—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É - –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
                        except Exception as e:
                            logger.debug(f"  ‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ {path}: {str(e)[:50]}")
                            pass  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é
                
                for contact_url in contact_urls:
                    if inn and emails:
                        break  # –£–∂–µ –≤—Å–µ –Ω–∞—à–ª–∏
                    
                    try:
                        logger.info(f"  ‚Üí –ó–∞–≥—Ä—É–∑–∫–∞: {contact_url}")
                        await page.goto(contact_url, wait_until='domcontentloaded', timeout=self.timeout)
                        result['source_urls'].append(page.url)
                        
                        contact_text = await self.get_page_text(page)
                        contact_html = await page.content()
                        
                        if not inn:
                            inn = self.extract_inn(contact_text, contact_html)
                            if inn:
                                result['inn'] = inn
                                logger.info(f"  ‚úÖ –ò–ù–ù –Ω–∞–π–¥–µ–Ω –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {inn}")
                        
                        if not emails:
                            new_emails = self.extract_emails(contact_text)
                            if new_emails:
                                result['emails'].extend(new_emails)
                                logger.info(f"  ‚úÖ Email –Ω–∞–π–¥–µ–Ω –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {new_emails}")
                        
                    except PlaywrightTimeout:
                        logger.warning(f"  ‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏: {contact_url}")
                    except Exception as e:
                        logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {contact_url}: {e}")
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã email
            result['emails'] = list(set(result['emails']))
            
            if result['inn'] or result['emails']:
                logger.info(f"‚úÖ {domain}: –ò–ù–ù={result['inn']}, Email={result['emails']}")
            else:
                logger.warning(f"‚ö†Ô∏è {domain}: –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except PlaywrightTimeout:
            error_msg = f"–¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"
            result['error'] = error_msg
            logger.error(f"‚ùå {domain}: {error_msg}")
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"
            result['error'] = error_msg
            logger.error(f"‚ùå {domain}: {error_msg}")
            
        finally:
            await page.close()
        
        return result
    
    async def parse_domains(self, domains: List[str]) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤.
        
        Args:
            domains: –°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–º–µ–Ω–∞
        """
        results = []
        
        for i, domain in enumerate(domains, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"–î–æ–º–µ–Ω {i}/{len(domains)}")
            logger.info(f"{'='*60}")
            
            result = await self.parse_domain(domain)
            results.append(result)
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            await asyncio.sleep(1)
        
        return results

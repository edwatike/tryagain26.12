"""Domain Info Parser - –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ò–ù–ù –∏ email —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü."""
import re
import asyncio
from typing import Optional, Dict, List
from urllib.parse import urljoin, urlparse
import logging

from playwright.async_api import async_playwright, Browser, Page, TimeoutError as PlaywrightTimeout

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DomainInfoParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ò–ù–ù –∏ email —Å –¥–æ–º–µ–Ω–æ–≤."""
    
    def __init__(self, headless: bool = True, timeout: int = 15000):
        """
        Args:
            headless: –ó–∞–ø—É—Å–∫–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä –≤ headless —Ä–µ–∂–∏–º–µ
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self.headless = headless
        self.timeout = timeout
        self.browser: Optional[Browser] = None
        self.playwright = None
        
    async def start(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä."""
        logger.info("–ó–∞–ø—É—Å–∫ Playwright...")
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=self.headless)
        logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω")
        
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å –±—Ä–∞—É–∑–µ—Ä."""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
    
    def extract_inn(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å –ò–ù–ù –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏."""
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ò–ù–ù —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        inn_patterns = [
            # –ü—Ä—è–º–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ò–ù–ù
            r'–ò–ù–ù[:\s]+(\d{10}|\d{12})',
            r'INN[:\s]+(\d{10}|\d{12})',
            r'–∏–Ω–Ω[:\s]+(\d{10}|\d{12})',
            # –° —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
            r'–ò–ù–ù[:\s]+(\d{4}[\s\-]?\d{6})',  # –ò–ù–ù: 1234 567890
            r'–ò–ù–ù[:\s]+(\d{4}[\s\-]?\d{4}[\s\-]?\d{4})',  # –ò–ù–ù: 1234 5678 9012
            # –í —Ç–∞–±–ª–∏—Ü–∞—Ö/—Ä–µ–∫–≤–∏–∑–∏—Ç–∞—Ö
            r'(?:—Ä–µ–∫–≤–∏–∑–∏—Ç|requisite|details).*?–ò–ù–ù[:\s]*(\d{10}|\d{12})',
            r'(?:—Ä–µ–∫–≤–∏–∑–∏—Ç|requisite|details).*?INN[:\s]*(\d{10}|\d{12})',
            # –†—è–¥–æ–º —Å –û–ì–†–ù/–ö–ü–ü
            r'(?:–û–ì–†–ù|OGRN).*?–ò–ù–ù[:\s]*(\d{10}|\d{12})',
            r'(?:–ö–ü–ü|KPP).*?–ò–ù–ù[:\s]*(\d{10}|\d{12})',
            # –í –∫–æ–Ω—Ç–∞–∫—Ç–∞—Ö/–æ –∫–æ–º–ø–∞–Ω–∏–∏
            r'(?:–æ –∫–æ–º–ø–∞–Ω–∏–∏|about|–∫–æ–Ω—Ç–∞–∫—Ç|contact).*?–ò–ù–ù[:\s]*(\d{10}|\d{12})',
        ]
        
        # –ò—â–µ–º —Å —è–≤–Ω—ã–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –ò–ù–ù
        for pattern in inn_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            for match in matches:
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –¥–µ—Ñ–∏—Å—ã
                clean_match = re.sub(r'[\s\-]', '', match)
                if len(clean_match) in [10, 12]:
                    logger.info(f"Found INN with pattern: {clean_match}")
                    return clean_match
        
        # –ü–æ–∏—Å–∫ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ "—Ä–µ–∫–≤–∏–∑–∏—Ç—ã" –∏–ª–∏ "–æ –∫–æ–º–ø–∞–Ω–∏–∏"
        context_patterns = [
            r'(?:—Ä–µ–∫–≤–∏–∑–∏—Ç|requisite|–æ –∫–æ–º–ø–∞–Ω–∏–∏|about|details|company info).*?(\d{10}|\d{12})',
        ]
        
        for pattern in context_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            for match in matches[:3]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                if len(match) in [10, 12] and not match.startswith(('7', '8', '9')):
                    logger.info(f"Found INN in context: {match}")
                    return match
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å —è–≤–Ω—ã–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º, –∏—â–µ–º 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥
        # –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –æ–∫—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏–ª–∏ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        general_pattern = r'(?<!\d)(\d{10}|\d{12})(?!\d)'
        matches = re.findall(general_pattern, text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –∏—Å–∫–ª—é—á–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –∏ –¥—Ä—É–≥–∏–µ —á–∏—Å–ª–∞
        for match in matches:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–µ–ª–µ—Ñ–æ–Ω (–Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 7, 8, 9)
            if len(match) == 10 and not match.startswith(('7', '8', '9')):
                logger.info(f"Found potential INN (10 digits): {match}")
                return match
            elif len(match) == 12:
                # –î–ª—è 12-–∑–Ω–∞—á–Ω—ã—Ö –ò–ù–ù (–ò–ü) –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 79 (—Ç–µ–ª–µ—Ñ–æ–Ω)
                if not match.startswith('79'):
                    logger.info(f"Found potential INN (12 digits, IP): {match}")
                    return match
        
        logger.info("No INN found in text")
        return None
    
    def extract_emails(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å email –∞–¥—Ä–µ—Å–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        emails = re.findall(pattern, text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –∏—Å–∫–ª—é—á–∞–µ–º –æ–±—â–∏–µ email-–∞–¥—Ä–µ—Å–∞ —Ç–∏–ø–∞ example@example.com
        filtered = []
        exclude_patterns = ['example', 'test', 'domain', 'email', 'yoursite', 'yourdomain']
        
        for email in emails:
            email_lower = email.lower()
            if not any(pattern in email_lower for pattern in exclude_patterns):
                filtered.append(email)
        
        return list(set(filtered))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    async def get_page_text(self, page: Page) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ body
            text = await page.evaluate('''() => {
                return document.body.innerText;
            }''')
            return text
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return ""
    
    async def find_contact_pages(self, page: Page, base_url: str) -> List[str]:
        """–ù–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏."""
        contact_keywords = ['–∫–æ–Ω—Ç–∞–∫—Ç', 'contact', '–æ –∫–æ–º–ø–∞–Ω–∏–∏', 'about', '—Ä–µ–∫–≤–∏–∑–∏—Ç']
        contact_urls = []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            links = await page.evaluate('''() => {
                return Array.from(document.querySelectorAll('a[href]')).map(a => ({
                    href: a.href,
                    text: a.innerText.toLowerCase()
                }));
            }''')
            
            for link in links:
                href = link['href']
                text = link['text']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                if any(keyword in text for keyword in contact_keywords):
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π URL
                    full_url = urljoin(base_url, href)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–æ—Ç –∂–µ –¥–æ–º–µ–Ω
                    if urlparse(full_url).netloc == urlparse(base_url).netloc:
                        contact_urls.append(full_url)
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü: {e}")
        
        return list(set(contact_urls))[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    
    async def parse_domain(self, domain: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏—Ç—å –¥–æ–º–µ–Ω –∏ –∏–∑–≤–ª–µ—á—å –ò–ù–ù –∏ email.
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, example.com)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {domain, inn, emails, source_urls, error}
        """
        if not self.browser:
            raise Exception("–ë—Ä–∞—É–∑–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω. –í—ã–∑–æ–≤–∏—Ç–µ start() —Å–Ω–∞—á–∞–ª–∞.")
        
        result = {
            'domain': domain,
            'inn': None,
            'emails': [],
            'source_urls': [],
            'error': None
        }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL
        url = f"https://{domain}" if not domain.startswith('http') else domain
        base_url = url
        
        logger.info(f"üîç –ü–∞—Ä—Å–∏–Ω–≥: {domain}")
        
        page = await self.browser.new_page()
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            logger.info(f"  ‚Üí –ó–∞–≥—Ä—É–∑–∫–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            await page.goto(url, wait_until='domcontentloaded', timeout=self.timeout)
            result['source_urls'].append(page.url)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            main_text = await self.get_page_text(page)
            
            # –ò—â–µ–º –ò–ù–ù –∏ email –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            inn = self.extract_inn(main_text)
            emails = self.extract_emails(main_text)
            
            if inn:
                result['inn'] = inn
                logger.info(f"  ‚úÖ –ò–ù–ù –Ω–∞–π–¥–µ–Ω –Ω–∞ –≥–ª–∞–≤–Ω–æ–π: {inn}")
            
            if emails:
                result['emails'].extend(emails)
                logger.info(f"  ‚úÖ Email –Ω–∞–π–¥–µ–Ω –Ω–∞ –≥–ª–∞–≤–Ω–æ–π: {emails}")
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ò–ù–ù –∏–ª–∏ email, –∏—â–µ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö
            if not inn or not emails:
                logger.info(f"  ‚Üí –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü...")
                contact_urls = await self.find_contact_pages(page, base_url)
                
                for contact_url in contact_urls:
                    if inn and emails:
                        break  # –£–∂–µ –≤—Å–µ –Ω–∞—à–ª–∏
                    
                    try:
                        logger.info(f"  ‚Üí –ó–∞–≥—Ä—É–∑–∫–∞: {contact_url}")
                        await page.goto(contact_url, wait_until='domcontentloaded', timeout=self.timeout)
                        result['source_urls'].append(page.url)
                        
                        contact_text = await self.get_page_text(page)
                        
                        if not inn:
                            inn = self.extract_inn(contact_text)
                            if inn:
                                result['inn'] = inn
                                logger.info(f"  ‚úÖ –ò–ù–ù –Ω–∞–π–¥–µ–Ω –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {inn}")
                        
                        if not emails:
                            new_emails = self.extract_emails(contact_text)
                            if new_emails:
                                result['emails'].extend(new_emails)
                                logger.info(f"  ‚úÖ Email –Ω–∞–π–¥–µ–Ω –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {new_emails}")
                        
                    except PlaywrightTimeout:
                        logger.warning(f"  ‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏: {contact_url}")
                    except Exception as e:
                        logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {contact_url}: {e}")
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã email
            result['emails'] = list(set(result['emails']))
            
            if result['inn'] or result['emails']:
                logger.info(f"‚úÖ {domain}: –ò–ù–ù={result['inn']}, Email={result['emails']}")
            else:
                logger.warning(f"‚ö†Ô∏è {domain}: –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except PlaywrightTimeout:
            error_msg = f"–¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"
            result['error'] = error_msg
            logger.error(f"‚ùå {domain}: {error_msg}")
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"
            result['error'] = error_msg
            logger.error(f"‚ùå {domain}: {error_msg}")
            
        finally:
            await page.close()
        
        return result
    
    async def parse_domains(self, domains: List[str]) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤.
        
        Args:
            domains: –°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–º–µ–Ω–∞
        """
        results = []
        
        for i, domain in enumerate(domains, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"–î–æ–º–µ–Ω {i}/{len(domains)}")
            logger.info(f"{'='*60}")
            
            result = await self.parse_domain(domain)
            results.append(result)
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            await asyncio.sleep(1)
        
        return results

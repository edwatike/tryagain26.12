# Оптимизация хранения данных Checko

## Текущий размер данных

### Размер на одну карточку поставщика:
- **Full checkoData JSON**: ~382 KB (391,281 bytes)
- **Индивидуальные поля**: ~50 bytes
- **Итого**: ~382 KB на одну карточку

### Требования к хранилищу:
- **1000 поставщиков**: ~382 MB
- **10000 поставщиков**: ~3.8 GB
- **100000 поставщиков**: ~38 GB

## Рекомендации по оптимизации

### 1. Сжатие JSON данных (gzip)

**Экономия**: ~70% (382 KB -> ~115 KB)

```python
import gzip
import json

def compress_checko_data(data: dict) -> bytes:
    """Compress Checko data using gzip."""
    json_str = json.dumps(data, ensure_ascii=False)
    return gzip.compress(json_str.encode('utf-8'))

def decompress_checko_data(compressed: bytes) -> dict:
    """Decompress Checko data."""
    json_str = gzip.decompress(compressed).decode('utf-8')
    return json.loads(json_str)
```

**Преимущества**:
- Простая реализация
- Автоматическое сжатие/распаковка
- Экономия ~70% места

**Недостатки**:
- Необходимо изменить тип поля на BYTEA
- Немного больше CPU при сохранении/загрузке

### 2. Хранение только необходимых данных

**Экономия**: ~80-90% (382 KB -> ~40-80 KB)

Разделить данные на:
- **Основные данные** (хранить в БД):
  - Базовая информация (name, OGRN, KPP, etc.)
  - Финансовые показатели (последний год)
  - Сводка по судебным делам
  - Сводка по проверкам
  
- **Детальные данные** (загружать по требованию):
  - Полная финансовая история
  - Детали судебных дел
  - Список учредителей
  - Детали проверок

**Преимущества**:
- Значительная экономия места
- Быстрая загрузка списка поставщиков
- Полные данные загружаются только при просмотре карточки

**Недостатки**:
- Необходимо изменить структуру данных
- Дополнительный запрос к Checko API при просмотре деталей

### 3. Использование PostgreSQL JSONB

**Экономия**: ~10-20% + лучшая производительность

```sql
-- Изменить тип поля
ALTER TABLE moderator_suppliers 
ALTER COLUMN checko_data TYPE JSONB USING checko_data::jsonb;

-- Создать индексы для быстрого поиска
CREATE INDEX idx_checko_data_finance_year 
ON moderator_suppliers ((checko_data->'_finances'));

CREATE INDEX idx_checko_data_legal_cases 
ON moderator_suppliers ((checko_data->'_legal'->>'ЗапВсего'));
```

**Преимущества**:
- Автоматическое сжатие PostgreSQL
- Индексирование для быстрого поиска
- Возможность запросов по JSON полям
- Валидация JSON на уровне БД

**Недостатки**:
- Необходима миграция
- Немного больше места для индексов

### 4. Архивация старых данных

**Экономия**: Зависит от политики архивации

Создать отдельную таблицу для архивных данных:
```sql
CREATE TABLE moderator_suppliers_archive (
    LIKE moderator_suppliers INCLUDING ALL
);
```

**Стратегия**:
- Перемещать неактивных поставщиков (>1 года без обновления)
- Хранить только активных в основной таблице
- Архивированные данные доступны по запросу

**Преимущества**:
- Основная таблица остается компактной
- Быстрые запросы по активным поставщикам
- История сохраняется

**Недостатки**:
- Необходимо реализовать логику архивации
- Дополнительная сложность при запросах

### 5. Комбинированный подход (рекомендуется)

**Оптимальная стратегия**:

1. **Сжатие данных** (gzip):
   - Экономия ~70% места
   - Минимальные изменения в коде

2. **JSONB вместо Text**:
   - Дополнительная экономия ~10-20%
   - Лучшая производительность запросов

3. **Архивация старых данных**:
   - Для долгосрочного хранения
   - Опционально, если данных много

**Ожидаемый результат**:
- **Текущий размер**: ~382 KB на карточку
- **После оптимизации**: ~80-100 KB на карточку
- **Экономия**: ~75-80%

## Реализация

### Приоритет 1: Сжатие данных (быстро, эффективно)
- Изменить тип поля `checko_data` на BYTEA
- Добавить функции сжатия/распаковки
- Обновить usecases для работы со сжатыми данными

### Приоритет 2: JSONB (средний приоритет)
- Создать миграцию для изменения типа поля
- Обновить модели SQLAlchemy
- Добавить индексы для частых запросов

### Приоритет 3: Архивация (низкий приоритет)
- Реализовать только при большом объеме данных (>10K поставщиков)
- Создать скрипт для архивации
- Обновить API для работы с архивом

## Мониторинг

Отслеживать:
- Размер базы данных
- Время выполнения запросов
- Использование дискового пространства
- Производительность API endpoints

## Пример расчета экономии

**Текущая ситуация**:
- 1000 поставщиков × 382 KB = 382 MB

**После оптимизации (сжатие + JSONB)**:
- 1000 поставщиков × 80 KB = 80 MB
- **Экономия**: 302 MB (79%)

**Для 10000 поставщиков**:
- Текущий: 3.8 GB
- После оптимизации: 800 MB
- **Экономия**: 3 GB (79%)

